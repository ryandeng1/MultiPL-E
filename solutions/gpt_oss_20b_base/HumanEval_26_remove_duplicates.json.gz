{"completions": ["```cpp\n#include <unordered_map>\n#include <vector>\n#include <cassert>\n\n/**\n * From a vector of integers, remove all elements that occur more than once.\n * Keep the order of the remaining elements the same as in the input.\n *\n * @param numbers The input vector.\n * @return A new vector containing only the elements that appeared once.\n */\nstd::vector<long> remove_duplicates(std::vector<long> numbers)\n{\n    // Count the frequency of every element\n    std::unordered_map<long, int> freq;\n    for (long v : numbers) {\n        ++freq[v];\n    }\n\n    // Build the result preserving original order\n    std::vector<long> result;\n    for (long v : numbers) {\n        if (freq[v] == 1) {\n            result.push_back(v);\n        }\n    }\n    return result;\n}\n\n// Example usage and simple test\nint main() {\n    std::vector<long> input{1, 2, 3, 2, 4};\n    std::vector<long> expected{1, 3, 4};\n    assert(remove_duplicates(input) == expected);\n    return 0;\n}\n```\n\nThis function first counts the occurrences of each value, then iterates over the original vector to copy only those values that appear exactly once, thus preserving the original order.", "```cpp\n#include <vector>\n#include <unordered_map>\n\nstd::vector<long> remove_duplicates(std::vector<long> numbers) {\n    std::unordered_map<long, int> freq;        // Count occurrences\n    for (const long n : numbers) {\n        ++freq[n];\n    }\n\n    std::vector<long> result;\n    result.reserve(numbers.size());           // Max possible size\n    for (const long n : numbers) {            // Preserve input order\n        if (freq[n] == 1) {\n            result.push_back(n);\n        }\n    }\n    return result;\n}\n```\n\n**Explanation**\n\n1. **Frequency table** \u2013 First loop builds a hash map (`freq`) that records how many times each number appears.\n2. **Filter** \u2013 Second loop walks through the original vector (`numbers`) in order and appends the value to `result` only if its count in `freq` is `1`.\n3. **Return** \u2013 The function returns `result` which contains all elements that were unique in the original vector, preserving the original order.", "Here\u2019s a simple and efficient implementation that keeps the original order but removes any value that appears more than once in the input vector:\n\n```cpp\n#include <vector>\n#include <unordered_set>\n\nstd::vector<long> remove_duplicates(const std::vector<long>& numbers) {\n    std::unordered_set<long> seen;          // Values that we have already encountered\n    std::unordered_set<long> dup;           // Values that have appeared more than once\n    std::vector<long> result;\n\n    for (long val : numbers) {\n        // If we already know this value is a duplicate, skip it\n        if (dup.count(val)) continue;\n\n        // If we have seen it once before, any further occurrence marks it as a duplicate\n        if (!seen.insert(val).second) {   // insert returns {iterator, bool}\n            dup.insert(val);\n            // The previous instance should be removed from the result\n            // Since we preserve order, we can simply discard new ones and later ignore the old\n            // For simplicity, we just skip adding this one \u2013 the old one was already in result\n            // We will remove it later if needed\n        }\n        else {\n            // First time we see this number \u2013 add to result for now\n            result.push_back(val);\n        }\n    }\n\n    // Now remove any previously added duplicates from the result\n    // Build the final list in the same order\n    std::vector<long> final;\n    for (long val : result) {\n        if (!dup.count(val)) final.push_back(val);\n    }\n    return final;\n}\n```\n\n### Explanation\n\n1. **`seen`** tracks values we\u2019ve already encountered.\n2. **`dup`** records values that appear more than once.\n3. If a value is seen for the second time, it\u2019s added to `dup`.\n4. After the loop, we filter the `result` vector, keeping only values that never became duplicates.\n\nThe algorithm is linear in the size of the input vector (O(n) time) with a small constant\u2011size overhead for the hash sets. It preserves the original order of the unique elements."]}